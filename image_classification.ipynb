{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import necessary modules\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5/train'\n",
    "test_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5/test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for using CNN to extract image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "def save_bottleneck_features(image_shape, batch_size, image_dir, filename):\n",
    "    ''' \n",
    "    Saves bottleneck features for testing and training.\n",
    "    '''\n",
    "    print('\\n Saving Bottleneck Features...')\n",
    "\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top = False)\n",
    "\n",
    "    if not(isfile(join(image_dir, filename))):\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range = 0,\n",
    "            width_shift_range = 0,\n",
    "            height_shift_range = 0,\n",
    "            shear_range = 0,\n",
    "            zoom_range = 0,\n",
    "            fill_mode = 'nearest'\n",
    "            )\n",
    "\n",
    "        image_generator = datagen.flow_from_directory(\n",
    "            image_dir,\n",
    "            target_size = image_shape,\n",
    "            batch_size = batch_size,\n",
    "            class_mode = None,\n",
    "            shuffle = False,\n",
    "            )\n",
    "\n",
    "        all_data = model.predict_generator(image_generator, verbose=1)\n",
    "        np.save(open(join(image_dir, filename),'wb'), all_data)\n",
    "    else:\n",
    "        all_data = np.load(join(image_dir, filename))\n",
    "        \n",
    "    return all_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for performing logistic regression with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for multinomial logistic regression (with parameter tuning)\n",
    "\n",
    "def perf_log_reg(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    s_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    X_train = s_scaler.fit_transform(X_train)\n",
    "    X_val = s_scaler.transform(X_val)\n",
    "\n",
    "    # x-validated parameter search on training data\n",
    "\n",
    "    lr = LogisticRegression(penalty='l2', multi_class='multinomial', solver='saga', max_iter=1000)\n",
    "    parameters = {'C':[0.0001, 0.001, 0.1, 1, 10]}\n",
    "#     parameters = {'C':[1, 10]}\n",
    "    clf = GridSearchCV(lr, parameters)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "\n",
    "    # evaluate on validation data\n",
    "\n",
    "    y_true, y_pred = y_val, clf.predict(X_val)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    return y_pred, y_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving Bottleneck Features...\n",
      "\n",
      " Saving Bottleneck Features...\n"
     ]
    }
   ],
   "source": [
    "# get the bottleneck features for the fully processed images\n",
    "\n",
    "# Model inputs\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "top_model_weights_path = 'my_model'\n",
    "\n",
    "image_shape = (224, 224) # VGG16\n",
    "\n",
    "# create bottleneck features for training data\n",
    "image_dir = train_data_dir\n",
    "filename = 'bottleneck_features_train.npy'\n",
    "train_data = save_bottleneck_features(image_shape, batch_size, image_dir,filename)\n",
    "train_data = np.reshape(train_data,(train_data.shape[0], 512*7*7))\n",
    "\n",
    "# and for testing data\n",
    "image_dir = test_data_dir\n",
    "filename = 'bottleneck_features_test.npy'\n",
    "test_data = save_bottleneck_features(image_shape, batch_size, image_dir, filename)\n",
    "test_data = np.reshape(test_data,(test_data.shape[0], 512*7*7))\n",
    "\n",
    "# # and for full set\n",
    "# image_dir = '/Users/rmillin/Documents/Insight/image_reorg/fullset'\n",
    "# filename = 'bottleneck_features'\n",
    "# all_data = save_bottleneck_features(image_shape, batch_size, image_dir, filename)\n",
    "# all_data = np.reshape(all_data,(all_data.shape[0], 512*7*7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the classifier optimization, training, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.382 (+/-0.129) for {'C': 0.0001}\n",
      "0.445 (+/-0.108) for {'C': 0.001}\n",
      "0.545 (+/-0.074) for {'C': 0.1}\n",
      "0.529 (+/-0.051) for {'C': 1}\n",
      "0.532 (+/-0.056) for {'C': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.41      0.42        32\n",
      "          1       0.80      0.88      0.84        32\n",
      "          2       0.51      0.69      0.59        32\n",
      "          3       0.76      0.69      0.72        32\n",
      "          4       0.74      0.53      0.62        32\n",
      "\n",
      "avg / total       0.65      0.64      0.64       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_classes = 5\n",
    "n_per_class_train = int(train_data.shape[0]/n_classes)\n",
    "n_per_class_test = int(test_data.shape[0]/n_classes)\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "for this_class in range(n_classes):\n",
    "    train_labels = train_labels + [this_class] * n_per_class_train\n",
    "    test_labels = test_labels + [this_class] * n_per_class_test\n",
    "  # labels\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# # set aside validation data\n",
    "# # because of rotations, groups of 4 images all belong to the same original image; preserve this\n",
    "# X_train, X_val, y_train, y_val = train_test_split(all_data, all_labels, test_size=0.2, stratify=all_labels)\n",
    "\n",
    "X_train = train_data\n",
    "X_val = test_data\n",
    "\n",
    "y_train = train_labels\n",
    "y_val = test_labels\n",
    "\n",
    "y_pred, y_true = perf_log_reg(X_train, X_val, y_train, y_val)\n",
    "\n",
    "np.save(open(os.path.join(test_data_dir,'pred_nn_filt.npy'),'wb'), y_pred)\n",
    "np.save(open(os.path.join(test_data_dir,'act_nn_filt.npy'),'wb'), y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the optimized classifier on the full dataset for use in the app (where images will be novel and not from either set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving Bottleneck Features...\n",
      "Found 1020 images belonging to 5 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e60a4881e183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_bottleneck_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bottleneck_features.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-002261cbd9a5>\u001b[0m in \u001b[0;36msave_bottleneck_features\u001b[0;34m(image_shape, batch_size, image_dir, filename)\u001b[0m\n\u001b[1;32m     35\u001b[0m             )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/insight/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/insight/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1528\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m             verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/envs/insight/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/insight/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/insight/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/insight/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/insight/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use all of this data for the model for classifying new images\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "image_dir = '/Users/rmillin/Documents/Insight/image_reorg/fullset'\n",
    "\n",
    "n_classes = 5\n",
    "\n",
    "all_data = save_bottleneck_features(image_shape, batch_size, image_dir, 'bottleneck_features.npy')\n",
    "all_data = np.reshape(all_data,(all_data.shape[0], 512*7*7))\n",
    "\n",
    "n_total = all_data.shape[0]\n",
    "n_per_class = int(n_total/n_classes)\n",
    "all_labels = []\n",
    "for this_class in range(n_classes):\n",
    "    all_labels = all_labels + [this_class] * n_per_class\n",
    "  # labels\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "s_scaler = preprocessing.MinMaxScaler()\n",
    "all_data = s_scaler.fit_transform(all_data)\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', C=0.1, multi_class='multinomial', solver='saga').fit(all_data, all_labels)\n",
    "# clf = LogisticRegression(penalty='l1', C=1, multi_class='multinomial', solver='saga').fit(all_data, all_labels)\n",
    "perf = clf.score(all_data, all_labels)\n",
    "print(perf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(join('/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/data',filename), 'wb'))\n",
    "filename = 'scaler.sav'\n",
    "pickle.dump(s_scaler, open(join('/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/data',filename), 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess performance on other pipelines: CNN features for unfiltered images, pixel values of unfiltered images, and pixel values of filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving Bottleneck Features...\n",
      "Found 840 images belonging to 5 classes.\n",
      "17/17 [==============================] - 691s 41s/step\n",
      "\n",
      " Saving Bottleneck Features...\n",
      "Found 160 images belonging to 5 classes.\n",
      "4/4 [==============================] - 126s 31s/step\n"
     ]
    }
   ],
   "source": [
    "# get the bottleneck features for the unfiltered images\n",
    "\n",
    "# Model inputs\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "top_model_weights_path = 'my_model'\n",
    "\n",
    "image_shape = (224, 224) # VGG16\n",
    "\n",
    "# create bottleneck features for training data\n",
    "image_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5_unfilt/train'\n",
    "filename = 'bottleneck_features_unfilt_train.npy'\n",
    "train_data = save_bottleneck_features(image_shape, batch_size, image_dir, filename)\n",
    "train_data = np.reshape(train_data,(train_data.shape[0], 512*7*7))\n",
    "\n",
    "# and for testing data\n",
    "image_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5_unfilt/test'\n",
    "filename = 'bottleneck_features_unfilt_test.npy'\n",
    "test_data = save_bottleneck_features(image_shape, batch_size, image_dir, filename)\n",
    "test_data = np.reshape(test_data,(test_data.shape[0], 512*7*7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.318 (+/-0.096) for {'C': 0.0001}\n",
      "0.387 (+/-0.122) for {'C': 0.001}\n",
      "0.480 (+/-0.064) for {'C': 0.1}\n",
      "0.464 (+/-0.090) for {'C': 1}\n",
      "0.463 (+/-0.101) for {'C': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.24      0.25      0.25        32\n",
      "          1       0.50      0.53      0.52        32\n",
      "          2       0.21      0.22      0.22        32\n",
      "          3       0.62      0.62      0.62        32\n",
      "          4       0.46      0.41      0.43        32\n",
      "\n",
      "avg / total       0.41      0.41      0.41       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get performance on CNN features for unfiltered images\n",
    "\n",
    "X_train = train_data\n",
    "X_val = test_data\n",
    "\n",
    "y_train = train_labels\n",
    "y_val = test_labels\n",
    "\n",
    "y_pred, y_true = perf_log_reg(X_train, X_val, y_train, y_val)\n",
    "\n",
    "np.save(open(os.path.join(image_dir,'pred_cnn_unfilt.npy'),'wb'), y_pred)\n",
    "np.save(open(os.path.join(image_dir,'act_cnn_unfilt.npy'),'wb'), y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      ".DS_Store\n",
      ".DS_Store\n",
      ".DS_Store\n",
      ".DS_Store\n"
     ]
    }
   ],
   "source": [
    "# also get accuracy for RGB values for filtered images\n",
    "\n",
    "import pdb\n",
    "import cv2\n",
    "\n",
    "train_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5/train'\n",
    "test_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5/test'\n",
    "\n",
    "animals = ['bear','canine','feline','hooved','others']\n",
    "    \n",
    "train_data=np.empty([0, 224**2])\n",
    "test_data=np.empty([0, 224**2])\n",
    "for animal in animals:\n",
    "    for name in os.listdir(os.path.join(train_data_dir,animal)):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(train_data_dir,animal,name))\n",
    "            train_data = np.append(train_data,np.matrix(img[:,:,0].flatten()),axis=0)\n",
    "        except:\n",
    "#            pdb.set_trace()\n",
    "            print(name)\n",
    "\n",
    "    for name in os.listdir(os.path.join(test_data_dir,animal)):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(test_data_dir,animal,name))\n",
    "            test_data = np.append(test_data,np.matrix(img[:,:,0].flatten()),axis=0)\n",
    "        except:\n",
    "    #        pdb.set_trace()\n",
    "            print(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.0001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.338 (+/-0.084) for {'C': 0.0001}\n",
      "0.323 (+/-0.074) for {'C': 0.001}\n",
      "0.325 (+/-0.096) for {'C': 0.1}\n",
      "0.327 (+/-0.105) for {'C': 1}\n",
      "0.329 (+/-0.099) for {'C': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        32\n",
      "          1       0.32      0.38      0.35        32\n",
      "          2       0.33      0.38      0.35        32\n",
      "          3       0.00      0.00      0.00        32\n",
      "          4       0.23      0.62      0.34        32\n",
      "\n",
      "avg / total       0.18      0.28      0.21       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classifier on filtered RGB\n",
    "\n",
    "X_train = train_data\n",
    "X_val = test_data\n",
    "\n",
    "y_pred, y_true = perf_log_reg(X_train, X_val, y_train, y_val)\n",
    "\n",
    "np.save(open(os.path.join(test_data_dir,'pred_rgb_filt.npy'),'wb'), y_pred)\n",
    "np.save(open(os.path.join(test_data_dir,'act_rgb_filt.npy'),'wb'), y_true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# performance on raw rgb values\n",
    "\n",
    "train_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5_unfilt/train'\n",
    "test_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5_unfilt/test'\n",
    "\n",
    "animals = ['bear','canine','feline','hooved','others']\n",
    "    \n",
    "train_data=np.empty([0, 224**2])\n",
    "test_data=np.empty([0, 224**2])\n",
    "for animal in animals:\n",
    "    for name in os.listdir(os.path.join(train_data_dir,animal)):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(train_data_dir,animal,name))\n",
    "            train_data = np.append(train_data,np.matrix(img[:,:,0].flatten()),axis=0)\n",
    "        except:\n",
    "#            pdb.set_trace()\n",
    "            print(name)\n",
    "\n",
    "    for name in os.listdir(os.path.join(test_data_dir,animal)):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(test_data_dir,animal,name))\n",
    "            test_data = np.append(test_data,np.matrix(img[:,:,0].flatten()),axis=0)\n",
    "        except:\n",
    "    #        pdb.set_trace()\n",
    "            print(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.346 (+/-0.056) for {'C': 0.0001}\n",
      "0.352 (+/-0.095) for {'C': 0.001}\n",
      "0.338 (+/-0.057) for {'C': 0.1}\n",
      "0.338 (+/-0.062) for {'C': 1}\n",
      "0.338 (+/-0.062) for {'C': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.31      0.12      0.18        32\n",
      "          1       0.55      0.50      0.52        32\n",
      "          2       0.47      0.50      0.48        32\n",
      "          3       0.00      0.00      0.00        32\n",
      "          4       0.19      0.44      0.26        32\n",
      "\n",
      "avg / total       0.30      0.31      0.29       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression on raw RGB\n",
    "\n",
    "X_train = train_data\n",
    "X_val = test_data\n",
    "\n",
    "y_pred, y_true = perf_log_reg(X_train, X_val, y_train, y_val)\n",
    "\n",
    "np.save(open(os.path.join(test_data_dir,'pred_rgb_unfilt.npy'),'wb'), y_pred)\n",
    "np.save(open(os.path.join(test_data_dir,'act_rgb_unfilt.npy'),'wb'), y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving Bottleneck Features...\n",
      "Found 840 images belonging to 5 classes.\n",
      " 4/17 [======>.......................] - ETA: 10:54"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Data inputs\n",
    "\n",
    "# Model inputs\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "top_model_weights_path = 'my_model'\n",
    "\n",
    "image_shape = (224, 224) # VGG16\n",
    "\n",
    "# train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/train'\n",
    "# test_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/test'\n",
    "# train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/multiclass/train_grayscale'\n",
    "# test_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/multiclass/test_grayscale'\n",
    "\n",
    "\n",
    "def save_bottleneck_features(image_shape, batch_size, test_data_dir, train_data_dir):\n",
    "    ''' \n",
    "    Saves bottleneck features for testing and training.\n",
    "    '''\n",
    "    print('\\n Saving Bottleneck Features...')\n",
    "\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top = False)\n",
    "\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range = 10,\n",
    "#         width_shift_range = 0.2,\n",
    "#         height_shift_range = 0.2,\n",
    "#         shear_range = 0,\n",
    "#         zoom_range = 0.2,\n",
    "#         fill_mode = 'nearest'\n",
    "#         )\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range = 0,\n",
    "        width_shift_range = 0,\n",
    "        height_shift_range = 0,\n",
    "        shear_range = 0,\n",
    "        zoom_range = 0,\n",
    "        fill_mode = 'nearest'\n",
    "        )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = image_shape,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        save_prefix='aug'  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "        )\n",
    "\n",
    "    if not(isfile('gray_all_bottleneck_features_train.npy')):\n",
    "        train_data = model.predict_generator(train_generator, verbose=1)\n",
    "        np.save(open(join(train_data_dir, 'bottleneck_features_train.npy'),'wb'), train_data)\n",
    "    else:\n",
    "        train_data = np.load(join(train_data_dir, 'bottleneck_features_train.npy'))\n",
    "        \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size = image_shape,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        save_prefix='aug'  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "        )\n",
    "            \n",
    "    if not(isfile(join(test_data_dir, 'bottleneck_features_test.npy'))):\n",
    "        test_data = model.predict_generator(test_generator, verbose=1)\n",
    "        np.save(open(join(test_data_dir, 'bottleneck_features_test.npy'),'wb'), test_data)\n",
    "    else:\n",
    "        test_data = np.load(join(test_data_dir, 'bottleneck_features_test.npy'))\n",
    "        \n",
    "    # with a Sequential model\n",
    "    layer_name = 'block3_pool'\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "    train_activations = intermediate_layer_model.predict_generator(train_generator)\n",
    "    test_activations = intermediate_layer_model.predict_generator(test_generator)\n",
    "\n",
    "    \n",
    "    train_y = to_categorical(train_generator.classes)\n",
    "    test_y = to_categorical(test_generator.classes)\n",
    "    train_labels = train_generator.class_indices\n",
    "    np.save(open(join(train_data_dir, 'train_y.npy'),'wb'), train_y)\n",
    "    np.save(open(join(test_data_dir, 'test_y.npy'),'wb'), test_y)\n",
    "        \n",
    "    return train_data, test_data, train_y, train_labels, test_y, train_activations, test_activations\n",
    "\n",
    "def train_top_model(train_data, train_y, test_data, test_y, n_classes, top_model_weights_path):\n",
    "    ''' \n",
    "    Train top layer with bottleneck features as input\n",
    "    '''\n",
    "\n",
    "    print('\\n Training the FC Layers...')\n",
    "   \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = train_data.shape[1:]))\n",
    "    model.add(Dense(2056, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1028, activation = 'relu'))\n",
    "    model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "    opt = optimizers.SGD(lr = 1.0e-4, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='model.best.hdf5', verbose=1, save_best_only=False)\n",
    "   \n",
    "    model.fit(train_data, train_y,\n",
    "             epochs=epochs,\n",
    "             batch_size=batch_size,\n",
    "             validation_data = [test_data, test_y],\n",
    "             callbacks = [checkpointer])\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "    return model  \n",
    "\n",
    "if (not isfile(join(train_data_dir, 'bottleneck_features_train.npy'))) or (not isfile(join(test_data_dir,'bottleneck_features_test.npy'))):\n",
    "    train_data, test_data, train_y, train_labels, test_y, train_activations, test_activations = \\\n",
    "        save_bottleneck_features(image_shape, \\\n",
    "        batch_size, test_data_dir, train_data_dir)\n",
    "else:\n",
    "    train_data = np.load(join(train_data_dir,'bottleneck_features_train.npy'))\n",
    "    test_data = np.load(join(test_data_dir, 'bottleneck_features_test.npy'))\n",
    "    train_y = np.load(train_data_dir,'train_y.npy')\n",
    "    test_y = np.load(test_data_dir, 'test_y.npy') \n",
    "    \n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
