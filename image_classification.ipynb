{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5/train'\n",
    "test_data_dir = '/Users/rmillin/Documents/Insight/image_reorg/fold5/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess all of the data together, then use xval within scikit-learn\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Data inputs\n",
    "\n",
    "# Model inputs\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "top_model_weights_path = 'my_model'\n",
    "\n",
    "image_shape = (224, 224) # VGG16\n",
    "\n",
    "image_dir = '/Users/rmillin/Documents/Insight/image_reorg/fullset'\n",
    "\n",
    "\n",
    "def save_bottleneck_features(image_shape, batch_size, image_dir):\n",
    "    ''' \n",
    "    Saves bottleneck features for testing and training.\n",
    "    '''\n",
    "    print('\\n Saving Bottleneck Features...')\n",
    "\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top = False)\n",
    "\n",
    "    if not(isfile(join(image_dir, 'bottleneck_features.npy'))):\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range = 0,\n",
    "            width_shift_range = 0,\n",
    "            height_shift_range = 0,\n",
    "            shear_range = 0,\n",
    "            zoom_range = 0,\n",
    "            fill_mode = 'nearest'\n",
    "            )\n",
    "\n",
    "        image_generator = datagen.flow_from_directory(\n",
    "            image_dir,\n",
    "            target_size = image_shape,\n",
    "            batch_size = batch_size,\n",
    "            class_mode = None,\n",
    "            shuffle = False,\n",
    "            )\n",
    "\n",
    "        all_data = model.predict_generator(image_generator, verbose=1)\n",
    "        np.save(open(join(image_dir, 'bottleneck_features.npy'),'wb'), all_data)\n",
    "    else:\n",
    "        all_data = np.load(join(image_dir, 'bottleneck_features.npy'))\n",
    "        \n",
    "    return all_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving Bottleneck Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/preprocessing/data.py:653: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self.scale_ = _handle_zeros_in_scale(np.sqrt(self.var_))\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.200 (+/-0.001) for {'C': 0.0001}\n",
      "0.200 (+/-0.001) for {'C': 0.001}\n",
      "0.581 (+/-0.039) for {'C': 0.1}\n",
      "0.581 (+/-0.043) for {'C': 1}\n",
      "0.583 (+/-0.051) for {'C': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-cb3889dc5a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "n_classes = 5\n",
    "\n",
    "all_data = save_bottleneck_features(image_shape, batch_size, image_dir)\n",
    "all_data = np.reshape(all_data,(all_data.shape[0], 512*7*7))\n",
    "\n",
    "n_total = all_data.shape[0]\n",
    "n_per_class = int(n_total/n_classes)\n",
    "all_labels = []\n",
    "for this_class in range(n_classes):\n",
    "    all_labels = all_labels + [this_class] * n_per_class\n",
    "  # labels\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# set aside validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_data, all_labels, test_size=0.2, stratify=all_labels)\n",
    "\n",
    "X_train = s_scaler.fit_transform(X_train)\n",
    "X_val = s_scaler.transform(X_val)\n",
    "\n",
    "# x-validated parameter search on training data\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=1, multi_class='multinomial', solver='saga').fit(train_data, train_labels)\n",
    "parameters = {'C':[0.0001, 0.001, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(lr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "\n",
    "# evaluate on validation data\n",
    "\n",
    "y_true, y_pred = y_val, clf.predict(X_val)\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.29      0.37        41\n",
      "          1       0.70      0.78      0.74        40\n",
      "          2       0.50      0.59      0.54        41\n",
      "          3       0.62      0.63      0.63        41\n",
      "          4       0.61      0.68      0.64        41\n",
      "\n",
      "avg / total       0.59      0.59      0.58       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/preprocessing/data.py:653: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self.scale_ = _handle_zeros_in_scale(np.sqrt(self.var_))\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "all_data = s_scaler.fit_transform(all_data)\n",
    "\n",
    "clf = LogisticRegression(penalty='l1', C=1, multi_class='multinomial', solver='saga').fit(all_data, all_labels)\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(join('/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/data',filename), 'wb'))\n",
    "filename = 'scaler.sav'\n",
    "pickle.dump(s_scaler, open(join('/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/data',filename), 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Data inputs\n",
    "\n",
    "# Model inputs\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "top_model_weights_path = 'my_model'\n",
    "\n",
    "image_shape = (224, 224) # VGG16\n",
    "\n",
    "# train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/train'\n",
    "# test_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/test'\n",
    "train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/downloads/sea_creatures/train'\n",
    "test_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/downloads/sea_creatures/test'\n",
    "\n",
    "\n",
    "def save_bottleneck_features(image_shape, batch_size, test_data_dir, train_data_dir):\n",
    "    ''' \n",
    "    Saves bottleneck features for testing and training.\n",
    "    '''\n",
    "    print('\\n Saving Bottleneck Features...')\n",
    "\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top = False)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range = 10,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        shear_range = 0,\n",
    "        zoom_range = 0.2,\n",
    "        fill_mode = 'nearest'\n",
    "        )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = image_shape,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        )\n",
    "\n",
    "    if not(os.path.isfile('sea_bottleneck_features_train.npy')):\n",
    "        train_data = model.predict_generator(train_generator, verbose=1)\n",
    "        np.save(open('sea_bottleneck_features_train.npy','wb'), train_data)\n",
    "    else:\n",
    "        train_data = np.load('bottleneck_features_train.npy')\n",
    "        \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size = image_shape,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False\n",
    "        )\n",
    "            \n",
    "    if not(os.path.isfile('sea_bottleneck_features_test.npy')):\n",
    "        test_data = model.predict_generator(test_generator, verbose=1)\n",
    "        np.save(open('sea_bottleneck_features_test.npy','wb'), test_data)\n",
    "    else:\n",
    "        test_data = np.load('weights/bottleneck_features_test.npy')\n",
    "        \n",
    "    # with a Sequential model\n",
    "    layer_name = 'block3_pool'\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "    train_activations = intermediate_layer_model.predict_generator(train_generator)\n",
    "    test_activations = intermediate_layer_model.predict_generator(test_generator)\n",
    "\n",
    "    \n",
    "    train_y = to_categorical(train_generator.classes)\n",
    "    test_y = to_categorical(test_generator.classes)\n",
    "    train_labels = train_generator.class_indices\n",
    "    np.save(open('train_y.npy','wb'), train_y)\n",
    "    np.save(open('test_y.npy','wb'), test_y)\n",
    "    np.save(open('train_labels.npy','wb'), train_labels)\n",
    "        \n",
    "    return train_data, test_data, train_y, train_labels, test_y, train_activations, test_activations\n",
    "\n",
    "def train_top_model(train_data, train_y, test_data, test_y, n_classes, top_model_weights_path):\n",
    "    ''' \n",
    "    Train top layer with bottleneck features as input\n",
    "    '''\n",
    "\n",
    "    print('\\n Training the FC Layers...')\n",
    "   \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = train_data.shape[1:]))\n",
    "    model.add(Dense(2056, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1028, activation = 'relu'))\n",
    "    model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "    opt = optimizers.SGD(lr = 1.0e-4, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='model.best.hdf5', verbose=1, save_best_only=False)\n",
    "   \n",
    "    model.fit(train_data, train_y,\n",
    "             epochs=epochs,\n",
    "             batch_size=batch_size,\n",
    "             validation_data = [test_data, test_y],\n",
    "             callbacks = [checkpointer])\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "    return model  \n",
    "\n",
    "if (not os.path.isfile('sea_bottleneck_features_train.npy')) or (not os.path.isfile('sea_bottleneck_features_test.npy')):\n",
    "    train_data, test_data, train_y, train_labels, test_y, train_activations, test_activations = \\\n",
    "        save_bottleneck_features(image_shape, \\\n",
    "        batch_size, test_data_dir, train_data_dir)\n",
    "else:\n",
    "    train_data = np.load('sea_bottleneck_features_train.npy')\n",
    "    test_data = np.load('sea_bottleneck_features_test.npy')\n",
    "    train_y = np.load('train_y.npy')\n",
    "    test_y = np.load('test_y.npy') \n",
    "    train_labels = np.load('train_labels.npy')\n",
    "    \n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saving Bottleneck Features...\n",
      "Found 840 images belonging to 5 classes.\n",
      " 4/17 [======>.......................] - ETA: 10:54"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Data inputs\n",
    "\n",
    "# Model inputs\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "top_model_weights_path = 'my_model'\n",
    "\n",
    "image_shape = (224, 224) # VGG16\n",
    "\n",
    "# train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/train'\n",
    "# test_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/test'\n",
    "# train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/multiclass/train_grayscale'\n",
    "# test_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/multiclass/test_grayscale'\n",
    "\n",
    "\n",
    "def save_bottleneck_features(image_shape, batch_size, test_data_dir, train_data_dir):\n",
    "    ''' \n",
    "    Saves bottleneck features for testing and training.\n",
    "    '''\n",
    "    print('\\n Saving Bottleneck Features...')\n",
    "\n",
    "\n",
    "    model = VGG16(weights=\"imagenet\", include_top = False)\n",
    "\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         rotation_range = 10,\n",
    "#         width_shift_range = 0.2,\n",
    "#         height_shift_range = 0.2,\n",
    "#         shear_range = 0,\n",
    "#         zoom_range = 0.2,\n",
    "#         fill_mode = 'nearest'\n",
    "#         )\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range = 0,\n",
    "        width_shift_range = 0,\n",
    "        height_shift_range = 0,\n",
    "        shear_range = 0,\n",
    "        zoom_range = 0,\n",
    "        fill_mode = 'nearest'\n",
    "        )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size = image_shape,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        save_prefix='aug'  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "        )\n",
    "\n",
    "    if not(isfile('gray_all_bottleneck_features_train.npy')):\n",
    "        train_data = model.predict_generator(train_generator, verbose=1)\n",
    "        np.save(open(join(train_data_dir, 'bottleneck_features_train.npy'),'wb'), train_data)\n",
    "    else:\n",
    "        train_data = np.load(join(train_data_dir, 'bottleneck_features_train.npy'))\n",
    "        \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size = image_shape,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        save_prefix='aug'  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "        )\n",
    "            \n",
    "    if not(isfile(join(test_data_dir, 'bottleneck_features_test.npy'))):\n",
    "        test_data = model.predict_generator(test_generator, verbose=1)\n",
    "        np.save(open(join(test_data_dir, 'bottleneck_features_test.npy'),'wb'), test_data)\n",
    "    else:\n",
    "        test_data = np.load(join(test_data_dir, 'bottleneck_features_test.npy'))\n",
    "        \n",
    "    # with a Sequential model\n",
    "    layer_name = 'block3_pool'\n",
    "    intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "    train_activations = intermediate_layer_model.predict_generator(train_generator)\n",
    "    test_activations = intermediate_layer_model.predict_generator(test_generator)\n",
    "\n",
    "    \n",
    "    train_y = to_categorical(train_generator.classes)\n",
    "    test_y = to_categorical(test_generator.classes)\n",
    "    train_labels = train_generator.class_indices\n",
    "    np.save(open(join(train_data_dir, 'train_y.npy'),'wb'), train_y)\n",
    "    np.save(open(join(test_data_dir, 'test_y.npy'),'wb'), test_y)\n",
    "        \n",
    "    return train_data, test_data, train_y, train_labels, test_y, train_activations, test_activations\n",
    "\n",
    "def train_top_model(train_data, train_y, test_data, test_y, n_classes, top_model_weights_path):\n",
    "    ''' \n",
    "    Train top layer with bottleneck features as input\n",
    "    '''\n",
    "\n",
    "    print('\\n Training the FC Layers...')\n",
    "   \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = train_data.shape[1:]))\n",
    "    model.add(Dense(2056, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1028, activation = 'relu'))\n",
    "    model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "    opt = optimizers.SGD(lr = 1.0e-4, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='model.best.hdf5', verbose=1, save_best_only=False)\n",
    "   \n",
    "    model.fit(train_data, train_y,\n",
    "             epochs=epochs,\n",
    "             batch_size=batch_size,\n",
    "             validation_data = [test_data, test_y],\n",
    "             callbacks = [checkpointer])\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "    return model  \n",
    "\n",
    "if (not isfile(join(train_data_dir, 'bottleneck_features_train.npy'))) or (not isfile(join(test_data_dir,'bottleneck_features_test.npy'))):\n",
    "    train_data, test_data, train_y, train_labels, test_y, train_activations, test_activations = \\\n",
    "        save_bottleneck_features(image_shape, \\\n",
    "        batch_size, test_data_dir, train_data_dir)\n",
    "else:\n",
    "    train_data = np.load(join(train_data_dir,'bottleneck_features_train.npy'))\n",
    "    test_data = np.load(join(test_data_dir, 'bottleneck_features_test.npy'))\n",
    "    train_y = np.load(train_data_dir,'train_y.npy')\n",
    "    test_y = np.load(test_data_dir, 'test_y.npy') \n",
    "    \n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-45109238d9ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 860 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "860/860 [==============================] - 3s 3ms/step - loss: -14.6079 - acc: 0.1953 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 5/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 9/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 10/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 11/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 12/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 13/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 14/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 15/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 16/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 17/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 18/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 19/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 20/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 21/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 22/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 25/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 26/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 28/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 29/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 30/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 32/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 34/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 36/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 37/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 40/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 41/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 42/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 44/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 45/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 46/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 47/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "860/860 [==============================] - 3s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "860/860 [==============================] - 3s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "860/860 [==============================] - 3s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 51/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 52/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 53/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 54/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 55/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 56/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 57/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 58/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 59/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 60/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 61/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 62/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 63/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 64/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 67/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 68/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 69/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 70/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 71/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 72/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 73/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 74/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 78/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 79/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 80/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 81/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 82/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 83/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "860/860 [==============================] - 2s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 89/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "860/860 [==============================] - 2s 2ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 98/100\n",
      "860/860 [==============================] - 609s 708ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 99/100\n",
      "860/860 [==============================] - 4s 4ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n",
      "Epoch 100/100\n",
      "860/860 [==============================] - 3s 3ms/step - loss: -15.9424 - acc: 0.2000 - val_loss: -15.9424 - val_acc: 0.2000\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(join(train_data_dir,'bottleneck_features_train.npy'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "# train_labels = np.array([0] * int(train_data.shape[0]/2) + [1] * int(train_data.shape[0]/2))\n",
    "# train_labels = np.array([0] * 69 + [1] * 70\n",
    "# train_labels = np.load(join(train_data_dir,'train_y.npy'))\n",
    "train_labels = np.array([0] * int(train_data.shape[0]/5) + [1] * int(train_data.shape[0]/5) + [2] * int(train_data.shape[0]/5) + [3] * int(train_data.shape[0]/5) + [4] * int(train_data.shape[0]/5))\n",
    "\n",
    "validation_data = np.load(join(test_data_dir, 'bottleneck_features_test.npy'))\n",
    "# validation_labels = np.array([0] * int(test_data.shape[0]/2) + [1] * int(test_data.shape[0]/2))\n",
    "# validation_labels = np.load(join(test_data_dir,'test_y.npy'))\n",
    "validation_labels = np.array([0] * int(validation_data.shape[0]/5) + [1] * int(validation_data.shape[0]/5) + [2] * int(validation_data.shape[0]/5) + [3] * int(validation_data.shape[0]/5) + [4] * int(validation_data.shape[0]/5))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 28, 28, 256)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(test_data.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(join(train_data_dir, 'bottleneck_features_train.npy'))\n",
    "train_data = np.reshape(train_data,(train_data.shape[0], 512*7*7))\n",
    "# train_data = np.reshape(train_activations,(train_activations.shape[0], 28*28*256))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "# train_labels = np.load('train_y.npy')\n",
    "# train_labels = train_labels[:,0]\n",
    "# train_labels = np.array([0] * int(train_data.shape[0]/2) + [1] * int(train_data.shape[0]/2))\n",
    "train_labels = np.array([0] * int(train_data.shape[0]/5) + [1] * int(train_data.shape[0]/5) + [2] * int(train_data.shape[0]/5) + [3] * int(train_data.shape[0]/5) + [4] * int(train_data.shape[0]/5))\n",
    "# train_labels = np.array([0] * 276 + [1] * 280)\n",
    "\n",
    "test_data = np.load(join(test_data_dir, 'bottleneck_features_test.npy'))\n",
    "test_data = np.reshape(test_data,(test_data.shape[0], 512*7*7))\n",
    "# test_labels = np.load('test_y.npy')\n",
    "# test_labels = test_labels[:,0]\n",
    "# test_data = np.reshape(test_activations,(test_activations.shape[0], 28*28*256))\n",
    "# test_labels = np.array([0] * int(test_data.shape[0]/2) + [1] * int(test_data.shape[0]/2))\n",
    "test_labels = np.array([0] * int(test_data.shape[0]/5) + [1] * int(test_data.shape[0]/5) + [2] * int(test_data.shape[0]/5) + [3] * int(test_data.shape[0]/5) + [4] * int(test_data.shape[0]/5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720\n",
      "860\n",
      "320\n",
      "160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum(train_labels))\n",
    "print(len(train_labels))\n",
    "print(np.sum(test_labels))\n",
    "print(len(test_labels))\n",
    "\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/preprocessing/data.py:653: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self.scale_ = _handle_zeros_in_scale(np.sqrt(self.var_))\n",
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 2 4 4 0 4 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 3 1\n",
      " 1 1 1 1 1 1 2 1 1 1 1 3 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 3 2 0 2 2 0 0 3 3 3 3 2 2 2 2 0 3 0 0 3 3 3 3 0 3 3 3 3 0 3\n",
      " 3 3 3 0 0 3 3 3 3 3 3 3 3 2 3 3 3 1 2 4 4 4 1 1 2 2 2 2 2 0 4 4 4 2 2 4 4\n",
      " 4 0 0 4 4 0 4 2 3 0 1 4]\n",
      "Accuracy of Logistic regression classifier on training set: 0.97\n",
      "Accuracy of Logistic regression classifier on test set: 0.62\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic regression classifier on features\n",
    "\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# train_data = train_activations\n",
    "# test_data = test_activations\n",
    "\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "train_data = s_scaler.fit_transform(train_data)\n",
    "test_data = s_scaler.transform(test_data)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', C=1, multi_class='multinomial', solver='saga').fit(train_data, train_labels)\n",
    "pred = clf.predict(test_data)\n",
    "\n",
    "print(pred)\n",
    "np.save(open(os.path.join(test_data_dir,'pred_nn_raw.npy'),'wb'), pred)\n",
    "np.save(open(os.path.join(test_data_dir,'act_nn_raw.npy'),'wb'), test_labels)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(train_data, train_labels)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(test_data, test_labels)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clf = SVC(C=0.00001,kernel='linear').fit(train_data, train_labels)\n",
    "pred = clf.predict(test_data)\n",
    "\n",
    "\n",
    "train_acc_nn = []\n",
    "test_acc_nn = []\n",
    "# param_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "param_range = [10**(-20), 10**(-15), 10**(-10), 0.000000001, 0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001]\n",
    "for this_C in param_range:\n",
    "    clf = LogisticRegression(penalty='l2', C=this_C, multi_class='multinomial', solver='saga').fit(train_data, train_labels)\n",
    "#     clf = SVC(C=this_C).fit(train_data, train_labels)\n",
    "    train_acc_nn = np.append(train_acc_nn,clf.score(train_data,train_labels))\n",
    "    test_acc_nn = np.append(test_acc_nn, clf.score(test_data,test_labels))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.title('Validation Curve with CNN Features')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "\n",
    "plt.semilogx(param_range, train_acc_nn, label='Training score')\n",
    "\n",
    "plt.semilogx(param_range, test_acc_nn, label='Testing score')\n",
    "\n",
    "#plt.show()    \n",
    "plt.savefig(os.path.join(test_data_dir,'NN_validation_L1.png'))    \n",
    "    \n",
    "    \n",
    "#import pdb    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title('Validation Curve with CNN Features')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "\n",
    "plt.semilogx(param_range, train_acc_nn, label='Training score')\n",
    "\n",
    "plt.semilogx(param_range, test_acc_nn, label='Testing score')\n",
    "\n",
    "#plt.show()    \n",
    "plt.savefig('NN_validation.png')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import cv2\n",
    "\n",
    "\n",
    "animals = ['bear','canine','feline','hooved','others']\n",
    "    \n",
    "# also get accuracy for RGB values\n",
    "training_data=np.empty([0, 224**2])\n",
    "testing_data=np.empty([0, 224**2])\n",
    "for animal in animals:\n",
    "    for name in os.listdir(os.path.join(train_data_dir,animal)):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(train_data_dir,animal,name))\n",
    "            training_data = np.append(training_data,np.matrix(img[:,:,0].flatten()),axis=0)\n",
    "        except:\n",
    "#            pdb.set_trace()\n",
    "            print(name)\n",
    "\n",
    "    for name in os.listdir(os.path.join(test_data_dir,animal)):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(test_data_dir,animal,name))\n",
    "            testing_data = np.append(testing_data,np.matrix(img[:,:,0].flatten()),axis=0)\n",
    "        except:\n",
    "    #        pdb.set_trace()\n",
    "            print(name)\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "training_data = min_max_scaler.fit_transform(training_data)\n",
    "testing_data = min_max_scaler.transform(testing_data)\n",
    "\n",
    "# train_acc_rgb = []\n",
    "# test_acc_rgb = []\n",
    "# for this_C in param_range:\n",
    "#     clf = LogisticRegression(penalty='l1', C=this_C).fit(training_data, train_labels)\n",
    "# #     clf = SVC(C=this_C).fit(training_data, training_labels)\n",
    "#     train_acc_rgb = np.append(train_acc_rgb,clf.score(training_data,training_labels))\n",
    "#     test_acc_rgb = np.append(test_acc_rgb,clf.score(testing_data,test_labels))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.title('Validation Curve with RGB Values')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('Score')\n",
    "# plt.ylim(0.0, 1.1)\n",
    "# lw = 2\n",
    "\n",
    "# plt.semilogx(param_range, train_acc_rgb, label='Training score')\n",
    "\n",
    "# plt.semilogx(param_range, test_acc_rgb, label='Testing score')\n",
    "\n",
    "# #plt.show()    \n",
    "# plt.savefig('RGB_validation.png')  \n",
    "\n",
    "# print(np.sum(training_labels))\n",
    "# print(len(training_labels))\n",
    "# print(np.sum(testing_labels))\n",
    "# print(len(testing_labels))\n",
    "\n",
    "# np.save(open('pred_intens_filt.npy','wb'), pred)\n",
    "# np.save(open('act_intens_filt.npy','wb'), test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(860, 50176)\n",
      "[0 0 0 2 4 2 0 4 1 4 2 4 0 4 4 4 1 1 1 1 4 0 0 0 0 3 4 1 1 1 1 2 2 2 3 0 1\n",
      " 3 0 2 4 4 4 4 1 2 1 2 1 2 2 3 4 4 4 4 1 3 0 0 4 1 0 4 4 0 3 2 0 0 2 0 4 0\n",
      " 0 3 0 3 3 3 4 4 0 2 0 2 0 2 3 0 3 0 2 3 0 0 1 1 0 4 4 4 4 4 2 4 4 1 0 1 2\n",
      " 4 1 0 1 2 3 3 0 2 1 1 2 4 2 4 2 4 4 4 4 4 1 2 0 4 4 1 4 4 4 1 4 4 4 1 4 2\n",
      " 0 2 1 4 4 1 4 4 4 4 4 4]\n",
      "Accuracy of Logistic regression classifier on training set: 0.27\n",
      "Accuracy of Logistic regression classifier on test set: 0.28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(training_data.shape)\n",
    "clf = LogisticRegression(penalty='l1',C=0.1).fit(training_data, train_labels)\n",
    "pred = clf.predict(testing_data)\n",
    "\n",
    "print(pred)\n",
    "np.save(open(os.path.join(test_data_dir,'pred_intens.npy'),'wb'), pred)\n",
    "np.save(open(os.path.join(test_data_dir,'act_intens.npy'),'wb'), test_labels)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(training_data, train_labels)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(testing_data, test_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 50, 50\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/train'\n",
    "validation_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/test'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(50,50,3))\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save('bottleneck_features_train.npy',\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save('bottleneck_features_validation.npy',\n",
    "            bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-ebbac4743027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get output from layer layer_name = 'my_layer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m intermediate_layer_model = Model(inputs=base_model.input,\n\u001b[0;32m----> 3\u001b[0;31m                                  outputs=base_model.get_layer(layer_name).output)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermediate_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer_name' is not defined"
     ]
    }
   ],
   "source": [
    "# get output from layer layer_name = 'my_layer'\n",
    "intermediate_layer_model = Model(inputs=base_model.input,\n",
    "                                 outputs=base_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([name for name in os.listdir('/Users/rmillin/Documents/Insight/animal-tracks/images/first_test/test/dog')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50*50*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rmillin/Documents/Insight/web-app/flaskexample/static/images/train/cougar/.DS_Store'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(train_dir,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 images belonging to 2 classes.\n",
      "train\n",
      "Found 23 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#     preprocessing_function=preprocess_input,\n",
    "\n",
    "train_datagen =  image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "#     preprocessing_function=preprocess_input,\n",
    "\n",
    "test_datagen = image.ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    vertical_flip=False,\n",
    "    horizontal_flip=False\n",
    ")\n",
    "#pdb.set_trace()\n",
    "batch_size_train = 16\n",
    "batch_size_test = 1\n",
    "# os.makedirs('train_images_aug')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/train',\n",
    "  target_size=(50,50),\n",
    "  batch_size=batch_size_train,\n",
    "  class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "  shuffle=False,\n",
    "  save_to_dir='train_images_aug', \n",
    "  save_prefix='aug')  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "for k in train_generator:\n",
    "    print('train')\n",
    "    break\n",
    "# os.makedirs('test_images_aug')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "  '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/test',\n",
    "  target_size=(50,50),\n",
    "  batch_size=batch_size_test,\n",
    "  class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "  shuffle=False,\n",
    "  save_to_dir='test_images_aug', \n",
    "  save_prefix='aug')  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 50, 50\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/train'\n",
    "validation_data_dir = '/Users/rmillin/Documents/Insight/animal-tracks/mvpapp/webapp/static/images/test'\n",
    "nb_train_samples = 92\n",
    "nb_validation_samples = 20\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "#    model = applications.VGG16(include_top=False, weights='imagenet', pooling='max')\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save('bottleneck_features_train.npy',\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save('bottleneck_features_validation.npy',\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190476190476191"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the bottleneck features to use for classification\n",
    "\n",
    "vgg_conv = VGG19(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(50, 50,3))\n",
    "\n",
    "bottleneck_features_train = vgg_conv.predict_generator(train_generator)\n",
    "# save the output as a Numpy array\n",
    "np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "\n",
    "bottleneck_features_test = vgg_conv.predict_generator(test_generator)\n",
    "# save the output as a Numpy array\n",
    "np.save('bottleneck_features_test.npy', bottleneck_features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the number of each class in train and test\n",
    "import fnmatch\n",
    "import os\n",
    "\n",
    "# -1 below for DSstore file.  NEED TO CHECK AND FIX!!!!\n",
    "n_dogs = 22\n",
    "n_cougars = 22\n",
    "train_labels = np.array([0] * n_cougars + [1] * n_dogs)\n",
    "\n",
    "n_dogs = 8\n",
    "n_cougars = 15\n",
    "# n_dogs = len([name for name in os.listdir('/Users/rmillin/Documents/Insight/animal-tracks/images/first_test/test/dog')])-1\n",
    "# n_cougars = len([name for name in os.listdir('/Users/rmillin/Documents/Insight/animal-tracks/images/first_test/test/cougar')])-1\n",
    "test_labels = np.array([0] * n_cougars + [1] * n_dogs)\n",
    "\n",
    "\n",
    "# load the data into numpy arrays\n",
    "train_data = np.squeeze(np.load('bottleneck_features_train.npy'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "\n",
    "test_data = np.squeeze(np.load('bottleneck_features_test.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1a5f82a080>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16(weights=\"imagenet\", include_top = False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block3_pool'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[10].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features from an arbitrary intermediate layer\n",
    "\n",
    "\n",
    "from vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
